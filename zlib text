import urllib.request
from bs4 import BeautifulSoup
import zlib # Import zlib module
import os
import time


def gettext(url):
  with urllib.request.urlopen(url) as response:
    html_content = response.read().decode('utf-8')
    soup = BeautifulSoup(html_content, 'html.parser')
    plain_text = soup.get_text(separator=' ', strip=True)
    return plain_text

def clean_website_text(text, start_marker=None, end_marker=None):
    processed_text = text
    if start_marker:
        start_index = processed_text.find(start_marker)
        if start_index != -1:
            processed_text = processed_text[start_index + len(start_marker):]
    if end_marker:
        end_index = processed_text.find(end_marker)
        if end_index != -1:
            processed_text = processed_text[:end_index]
    return processed_text

text_url = "https://science.nasa.gov/photojournal/d-star-panorama-by-opportunity/"

start_time = time.time()

website_text = gettext(text_url)

cleaned_output = clean_website_text(
    website_text,
    start_marker="Description ",
    end_marker="Keep Exploring"
)

# Compress with zlib
content_bytes = cleaned_output.encode('utf-8')
compressed_data_zlib = zlib.compress(content_bytes)

# Save to file
with open('compressed_file_zlib.txt.zlib', 'wb') as f_out:
    f_out.write(compressed_data_zlib)

end_time = time.time()
duration_ns = (end_time - start_time) * 1_000_000_000

print(f"Original text content size (bytes): {len(content_bytes)}")
print(f"Compressed file size (compressed_file_zlib.txt.zlib): {os.path.getsize('compressed_file_zlib.txt.zlib')} bytes")
print(f"Execution time (zlib): {duration_ns:.2f} nanoseconds")
